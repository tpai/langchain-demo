{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf4ca8-08cc-4dea-a936-f6c21caa2212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de61d31b-94e6-4e53-bd45-2743021421f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os\n",
    "# os.environ['OPENAI_API_KEY'] = '...'\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "text_splitter = CharacterTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5c3e0e5-1f8d-4a80-9c69-46ff413524bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "with open('./data/llm_and_writing.txt') as f:\n",
    "    data = f.read()\n",
    "texts = text_splitter.split_text(data)\n",
    "print(len(texts))\n",
    "docs = [Document(page_content=t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41c068c0-bf66-49fe-a03f-5a75bea42add",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This article discusses the use of large-language models, such as OpenAI's GPT-4, and compares them to a Xerox photocopier. It suggests that these models are capable of compressing information and producing plausible, but incorrect, results, and that they cannot replace the process of writing original work. It argues that the time and effort spent on unoriginal work is necessary to gain the skills needed to write something original, and that it is only in the process of writing that one discovers their original ideas.\n",
      "token used:  5799\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "with get_openai_callback() as cb:\n",
    "    result = chain.run(docs)\n",
    "    print(result)\n",
    "    print(\"token used: \", cb.total_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
